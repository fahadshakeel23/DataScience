{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahadshakeel23/DataScience/blob/main/PM_MLS2_AnimeRatings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-Z3P5gYC-Nr"
      },
      "source": [
        "<center><img src=\"https://cdn.pixabay.com/photo/2017/04/25/05/14/samurai-2258604_960_720.jpg\" width=\"720\"></center>\n",
        "\n",
        "<center><font size=6>Anime Ratings Case Study</font></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj3ZBcwc-qTr"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVvNF5yJC-N8"
      },
      "source": [
        "### Business Context\n",
        "\n",
        "Streaming media services facilitate on-demand or real-time presentation and distribution of audio, video, and multimedia content across a communications route without downloading the files to their systems. This saves users time and storage, and at the same time provides the media owners with built-in copy protection. In today's digital space, streaming has become an influential medium for accessing information. Improved connectivity and advancement in technology have made streaming services accessible to almost everyone having an internet connection, and the surging demand for on-demand entertainment services such as entertainment programs and live matches is boosting the adoption of streaming media services globally.\n",
        "\n",
        "Streamist is a streaming company that streams web series and movies to a worldwide audience. Every content on their portal is rated by the viewers, and the portal also provides other information for the content like the number of people who have watched it, the number of people who want to watch it, the number of episodes, duration of an episode, etc.\n",
        "\n",
        "\n",
        "### Objective\n",
        "\n",
        "Streamist is currently focusing on the anime available in their portal and wants to identify the most important factors involved in rating an anime.  As a data scientist at Streamist, you are tasked with analyzing the  portal's anime data and identifying the important factors by building a predictive model to predict the rating of an anime.\n",
        "\n",
        "\n",
        "\n",
        "### Data Dictionary\n",
        "\n",
        "Each record in the database provides a description of an anime. A detailed data dictionary can be found below.\n",
        "\n",
        "1. title: title of the anime\n",
        "2. mediaType: format of publication\n",
        "3. eps: number of episodes (movies are considered 1 episode)\n",
        "4. duration: duration of an episode in minutes\n",
        "5. startYr: the year that airing started\n",
        "6. finishYr: the year that airing finished\n",
        "7. description: the synopsis of the plot\n",
        "8. contentWarn: content warning\n",
        "9. watched: number of users that completed it\n",
        "10. watching: number of users that are watching it\n",
        "11. rating: average user rating\n",
        "12. votes: number of votes that contribute to the rating\n",
        "13. studio_primary: studios responsible for creation\n",
        "14. studios_colab: whether there was a collaboration between studios for anime production\n",
        "15. genre: genre to which the anime belongs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing  and Importing Necessary Libraries\n"
      ],
      "metadata": {
        "id": "F3Tm5SxJTle6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the libraries with the specified version.\n",
        "!pip install pandas==2.0.3 numpy==1.25.2 seaborn==0.13.1 matplotlib==3.7.1 scikit-learn==1.2.2 statsmodels==0.14.2 -q --user"
      ],
      "metadata": {
        "id": "2eYSE2gLTseW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0555aef-0cd8-4502-d000-024a0b03f32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.11 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.1 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.2 which is incompatible.\n",
            "mizani 0.13.3 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "blosc2 3.3.1 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.2 which is incompatible.\n",
            "xarray 2025.3.1 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: *After running the above cell, kindly restart the notebook kernel / runtime and run all cells after this note sequentially.*"
      ],
      "metadata": {
        "id": "LqJnLu-fm2_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1OMxQ78FIOG"
      },
      "outputs": [],
      "source": [
        "# Libraries to help with reading and manipulating data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "\n",
        "# split the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to build linear regression_model\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# to check model performance\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxhpZv9y-qTw"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IhpfhVpKO5W"
      },
      "outputs": [],
      "source": [
        "# uncomment and run the following lines for mounting Google Drive to the notebook (to be used only if executing in Google Colab)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1w7UuCkFTtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac5e46d-ac4e-418a-a411-6595139e475d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'anime_ratings_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-902c68b6453c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"anime_ratings_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'anime_ratings_data.csv'"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"anime_ratings_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aodMV5D3-qTy"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-5jUOgu-qTz"
      },
      "source": [
        "The initial steps to get an overview of any dataset is to:\n",
        "- observe the first few rows of the dataset, to check whether the dataset has been loaded properly or not\n",
        "- get information about the number of rows and columns in the dataset\n",
        "- find out the data types of the columns to ensure that data is stored in the preferred format and the value of each property is as expected.\n",
        "- check the statistical summary of the dataset to get an overview of the numerical columns of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlzqMR1K-qTz"
      },
      "source": [
        "### Displaying the first few rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oT7wt_c-qT0"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0WQYOcl-qT0"
      },
      "source": [
        "* The dataset contains information about different anime\n",
        "* Many anime seem to have a single episode only, which are movies\n",
        "* Description seems to be missing for some anime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQi5ygTC-qT1"
      },
      "source": [
        "### Checking the shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9I7p2d5-qT1"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJt4J3px-qT1"
      },
      "source": [
        "* The dataset contains information (15 attributes) about 6523 anime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TcqcxbK-qT3"
      },
      "source": [
        "### Checking the data types of the columns for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AERVi7V5-qT4"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USTWGdhn-qT4"
      },
      "source": [
        "* There are 8 numeric (*float* and *int* type) and 7 string (*object* type) columns in the data\n",
        "* The target variable is the rating of an anime, which is of *float* type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUCorhch-qT4"
      },
      "source": [
        "### Statistical summary of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYAOucxD-qT4"
      },
      "outputs": [],
      "source": [
        "data.describe(include=\"all\").T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBFm-rJo-qT5"
      },
      "source": [
        "* We can see that the anime ratings vary between 1.1 and 4.7, which suggests that the anime were rated on a scale of 0-5\n",
        "* The general rating of anime is 2.96\n",
        "* *TV* is the most occurring type of media.\n",
        "* The number of views for the anime in the data varies from 5 to ~5000\n",
        "* The number of votes received by an anime in the data varies from 10 to 3100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNr4bWoM-qT5"
      },
      "source": [
        "### Checking for duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgVk5F0-C-OT"
      },
      "outputs": [],
      "source": [
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGlBm81cC-OT"
      },
      "source": [
        "* There are no duplicate values in the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch_TjRfF-qT5"
      },
      "source": [
        "### Checking for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaHeNmvo-qT6"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjQof-y7-qT6"
      },
      "source": [
        "* There are missing values in many columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoL1qjt7-qT6"
      },
      "outputs": [],
      "source": [
        "# creating a copy of the data so that original data remains unchanged\n",
        "df = data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjmJBEKSQjcH"
      },
      "source": [
        "## <a name='link2'>Exploratory Data Analysis (EDA) Summary</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftd1CbHOB6PZ"
      },
      "source": [
        "### **Note**: The EDA section has been covered multiple times in the previous case studies. In this case study, we will mainly focus on the model building aspects. We will only be looking at the key observations from EDA. The detailed EDA can be found in the <a href = #link1>appendix section</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe4tCS5PCFZk"
      },
      "source": [
        "**The below functions need to be defined to carry out the EDA.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoEbORxyCIcS"
      },
      "outputs": [],
      "source": [
        "def histogram_boxplot(data, feature, figsize=(15, 10), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (15,10))\n",
        "    kde: whether to show the density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a triangle will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR4f_2DVCK_K"
      },
      "outputs": [],
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(data[feature])  # length of the column\n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 2, 6))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 2, 6))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=data,\n",
        "        x=feature,\n",
        "        hue=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=data[feature].value_counts().index[:n],\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs74uLkiCMQH"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"rating\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf5FSgDYCpvG"
      },
      "source": [
        "* The anime ratings are close to normally distributed with fatter tails\n",
        "* Anime are rated approximately 3 by viewers on average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymUF8aiqCz98"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"duration\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D69kGfTSCzGe"
      },
      "source": [
        "* The distribution for duration column is right-skewed with a median runtime of less than 10 minutes\n",
        "* There are a few anime with episodes having 1 hour or more runtime, and are likely to be movies\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGgxXwFSDNzt"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"watched\", bins=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpFmNJEIDOuI"
      },
      "source": [
        "* The distribution for watched is heavily right-skewed, and most of the anime having less than 500 viewers\n",
        "* There is a spike at ~4500 in the histogram, indicating that there are anime which have been viewed by a lot of users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NADGNkM-DaUG"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"watching\", bins=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC5aOj3RDY15"
      },
      "source": [
        "* The distribution for `watching` is heavily right-skewed, and most of the anime have less than 50 current viewers\n",
        "* There is a spike at ~200 in the histogram, indicating that there are anime which are being viewed by a lot of users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5NIbE-0EIwq"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(df, \"mediaType\", perc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN1Ny6uBEDDU"
      },
      "source": [
        "* Approximately one-third of the anime have been released for TV\n",
        "* 9% of the anime have been released as web series, which is a little surprising"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD8YQ2heGMiu"
      },
      "outputs": [],
      "source": [
        "# creating a list of numerical columns\n",
        "num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# dropping start and finish year from list of numerical columns as they are not numerical in nature\n",
        "num_cols.remove(\"startYr\")\n",
        "num_cols.remove(\"finishYr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cx-I-saF_Pk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "sns.heatmap(\n",
        "    df[num_cols].corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\"\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AHCHBVZGAXF"
      },
      "source": [
        "* The rating of an anime is highly correlated with the number of people who have watched the anime and voted for it on the portal\n",
        "* The number of people who have watched the anime is highly correlated with the number of people who are watching the anime\n",
        "* The number of people who have watched the anime is very highly correlated with the number of people who have voted for the anime on the portal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nLQjELfIW3Z"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"mediaType\", y=\"rating\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRUCZOJMIYWn"
      },
      "source": [
        "* Anime available as web series or music videos have a lower rating in general"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P8Mwv1DGb8w"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "sns.boxplot(data=df, x=\"genre\", y=\"rating\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM_HXGIKGug6"
      },
      "source": [
        "* Anime under the genre of Drama are rated the highest in general, while those under the genre of Comedy and rated the least"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf4p3w3wGept"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "sns.boxplot(data=df, x=\"genre\", y=\"watched\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivNZL3tcGeNU"
      },
      "source": [
        "* Anime under the genres of Drama and Romance have higher viewership in general"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAI-7QM5Gfnc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "sns.boxplot(data=df, x=\"genre\", y=\"watching\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCiTS3VSIl-k"
      },
      "source": [
        "* Anime from the Drama and Romance genres are being watched more in general"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L1vPUuIlMVl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"mediaType\", y=\"duration\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8c5wTb_lMVm"
      },
      "source": [
        "* Anime released as movies or TV speicals have the highest duration while music videos have the lowest, which is expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ5wsxwA-qUG"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYF-RsrNqH0E"
      },
      "source": [
        "### Missing Value Treatment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvXgF1J3-qUH"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AFN0aGk-qUH"
      },
      "source": [
        "Let's fix the missing values in the data.\n",
        "\n",
        "- For the variable `mediaType`, we will impute the missing values with '*Other*' as the exact values for that category are not known\n",
        "- For the variables `duration` and `votes`, we will impute the missing values in each column with the median grouped by `genre` and `mediaType` as both the columns have skewed distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDbSvjhR-qUH"
      },
      "outputs": [],
      "source": [
        "# we first create a copy of the data to avoid changes to it\n",
        "df1 = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_nkqf4I-qUI"
      },
      "outputs": [],
      "source": [
        "df1.mediaType.fillna(\"Other\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkPvobr4-qUI"
      },
      "outputs": [],
      "source": [
        "df1[\"duration\"] = df1[\"duration\"].fillna(\n",
        "    value=df1.groupby([\"genre\", \"mediaType\"])[\"duration\"].transform(\"median\")\n",
        ")\n",
        "df1[\"votes\"] = df1[\"votes\"].fillna(\n",
        "    value=df1.groupby([\"genre\", \"mediaType\"])[\"votes\"].transform(\"median\")\n",
        ")\n",
        "\n",
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4zHqWJf-qUI"
      },
      "source": [
        "* We will impute the remaining missing values in the `duration` column with the median grouped by `genre`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99vleHsL-qUI"
      },
      "outputs": [],
      "source": [
        "df1[\"duration\"] = df1[\"duration\"].fillna(\n",
        "    value=df1.groupby([\"genre\"])[\"duration\"].transform(\"median\")\n",
        ")\n",
        "\n",
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VANP78tq-qUJ"
      },
      "source": [
        "- All the missing values have been treated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqLh_w63-qUJ"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0jUAxDX-qUJ"
      },
      "source": [
        "* Let's create a new feature `years_running` by taking the difference between `finishYr` and `startYr` columns\n",
        "* We will drop the original columns once the new feature is created as the year values themselves are not numerical in nature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFWtCpE7-qUJ"
      },
      "outputs": [],
      "source": [
        "df1[\"years_running\"] = df1[\"finishYr\"] - df1[\"startYr\"]\n",
        "df1.drop([\"startYr\", \"finishYr\"], axis=1, inplace=True)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeuhzPWVbtGq"
      },
      "source": [
        "### Outlier Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhFdx_FnNAC8"
      },
      "outputs": [],
      "source": [
        "# outlier detection using boxplot\n",
        "num_cols = df1.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, variable in enumerate(num_cols):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    sns.boxplot(data=df1, x=variable)\n",
        "    plt.tight_layout(pad=2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR_WgxyUE0uU"
      },
      "source": [
        "- There are quite a few outliers in the data\n",
        "- However, we will not treat them as they are proper values\n",
        "- We will drop the columns `title` and `description` as they contain a lot of text and too many unique values, and can be excluded from modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qsAAvsO-qUL"
      },
      "outputs": [],
      "source": [
        "df1.drop([\"title\", \"description\"], axis=1, inplace=True)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1THqC335b4Yi"
      },
      "source": [
        "### Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUSYueQxAngg"
      },
      "source": [
        "- We want to predict the rating of an anime\n",
        "- Before we proceed to build a model, we'll have to encode categorical features\n",
        "- We'll split the data into train and test to be able to evaluate the model that we build on the train data\n",
        "- We will build a Linear Regression model using the train data and then check it's performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "372WHRhJGpj4"
      },
      "outputs": [],
      "source": [
        "# defining X and y variables\n",
        "X = df1.drop([\"rating\"], axis=1)\n",
        "y = df1[\"rating\"]\n",
        "\n",
        "print(X.head())\n",
        "print(y.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3dbod_t-qUM"
      },
      "outputs": [],
      "source": [
        "# let's add the intercept to data\n",
        "X = sm.add_constant(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHEOjrb8N-4b"
      },
      "outputs": [],
      "source": [
        "# creating dummy variables\n",
        "X = pd.get_dummies(\n",
        "    X,\n",
        "    columns=X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist(),\n",
        "    drop_first=True\n",
        ")\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the input attributes into float type for modeling\n",
        "X = X.astype(float)\n",
        "X.head()"
      ],
      "metadata": {
        "id": "9foPJnDLL_8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBXfTtAPGoaF"
      },
      "outputs": [],
      "source": [
        "# splitting the data in 70:30 ratio for train to test data\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drw9GAU5-qUN"
      },
      "outputs": [],
      "source": [
        "print(\"Number of rows in train data =\", x_train.shape[0])\n",
        "print(\"Number of rows in test data =\", x_test.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9_JGYY_-qUN"
      },
      "source": [
        "## Model Building - Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ_s8bVsH3hu",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "olsmodel = sm.OLS(y_train, x_train).fit()\n",
        "print(olsmodel.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSK7ThIK1Le2"
      },
      "source": [
        "### Interpreting the Regression Results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUO-aovo1L6i"
      },
      "source": [
        "1. **Adjusted. R-squared**: It reflects the fit of the model.\n",
        "    - Adjusted R-squared values generally range from 0 to 1, where a higher value generally indicates a better fit, assuming certain conditions are met.\n",
        "    - In our case, the value for adj. R-squared is **0.722**, which is good.\n",
        "\n",
        "\n",
        "2. ***const* coefficient**: It is the Y-intercept.\n",
        "    - It means that if all the predictor variable coefficients are zero, then the expected output (i.e., Y) would be equal to the *const* coefficient.\n",
        "    - In our case, the value for `const` coefficient is **2.7707**\n",
        "\n",
        "\n",
        "3. **Coefficient of a predictor variable**: It represents the change in the output Y due to a change in the predictor variable (everything else held constant).\n",
        "    - In our case, the coefficient of `duration` is **0.0123**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhWcTffM-qUN"
      },
      "source": [
        "### Model Performance Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a7pUm3x-qUN"
      },
      "source": [
        "Let's check the performance of the model using different metrics.\n",
        "\n",
        "* We will be using metric functions defined in sklearn for RMSE, MAE, and $R^2$.\n",
        "* We will define a function to calculate MAPE and adjusted $R^2$.\n",
        "    - The mean absolute percentage error (MAPE) measures the accuracy of predictions as a percentage, and can be calculated as the average absolute percent error for each predicted value minus actual values divided by actual values. It works best if there are no extreme values in the data and none of the actual values are 0.\n",
        "    \n",
        "* We will create a function which will print out all the above metrics in one go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deaapIIvlJIL"
      },
      "outputs": [],
      "source": [
        "# function to compute adjusted R-squared\n",
        "def adj_r2_score(predictors, targets, predictions):\n",
        "    r2 = r2_score(targets, predictions)\n",
        "    n = predictors.shape[0]\n",
        "    k = predictors.shape[1]\n",
        "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
        "\n",
        "\n",
        "# function to compute MAPE\n",
        "def mape_score(targets, predictions):\n",
        "    return np.mean(np.abs(targets - predictions) / targets) * 100\n",
        "\n",
        "\n",
        "# function to compute different metrics to check performance of a regression model\n",
        "def model_performance_regression(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check regression model performance\n",
        "\n",
        "    model: regressor\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    r2 = r2_score(target, pred)  # to compute R-squared\n",
        "    adjr2 = adj_r2_score(predictors, target, pred)  # to compute adjusted R-squared\n",
        "    rmse = np.sqrt(mean_squared_error(target, pred))  # to compute RMSE\n",
        "    mae = mean_absolute_error(target, pred)  # to compute MAE\n",
        "    mape = mape_score(target, pred)  # to compute MAPE\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAE\": mae,\n",
        "            \"R-squared\": r2,\n",
        "            \"Adj. R-squared\": adjr2,\n",
        "            \"MAPE\": mape,\n",
        "        },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVBBaPtf-BZd"
      },
      "outputs": [],
      "source": [
        "# checking model performance on train set (seen 70% data)\n",
        "print(\"Training Performance\\n\")\n",
        "olsmodel_train_perf = model_performance_regression(olsmodel, x_train, y_train)\n",
        "olsmodel_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv51vNBhlJIL"
      },
      "outputs": [],
      "source": [
        "# checking model performance on test set (seen 30% data)\n",
        "print(\"Test Performance\\n\")\n",
        "olsmodel_test_perf = model_performance_regression(olsmodel, x_test, y_test)\n",
        "olsmodel_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FQ3kqwZ-qUO"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "- The training $R^2$ is 0.72, so the model is not underfitting\n",
        "\n",
        "- The train and test RMSE and MAE are comparable, so the model is not overfitting either\n",
        "\n",
        "- MAE suggests that the model can predict anime ratings within a mean error of 0.34 on the test data\n",
        "\n",
        "- MAPE of 12.6 on the test data means that we are able to predict within 12.6% of the anime ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9GxSQf-qH8e"
      },
      "source": [
        "## Checking Linear Regression Assumptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wr6XkwoqH8f"
      },
      "source": [
        "We will be checking the following Linear Regression assumptions:\n",
        "\n",
        "1. **No Multicollinearity**\n",
        "\n",
        "2. **Linearity of variables**\n",
        "\n",
        "3. **Independence of error terms**\n",
        "\n",
        "4. **Normality of error terms**\n",
        "\n",
        "5. **No Heteroscedasticity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mROHQdzZqH8f"
      },
      "source": [
        "### TEST FOR MULTICOLLINEARITY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul6gKpZqIZ6M"
      },
      "source": [
        "* Multicollinearity occurs when predictor variables in a regression model are correlated. This correlation is a problem because predictor variables should be independent. If the correlation between variables is high, it can cause problems when we fit the model and interpret the results. When we have multicollinearity in the linear model, the coefficients that the model suggests are unreliable.\n",
        "\n",
        "* There are different ways of detecting (or testing) multicollinearity. One such way is by using the Variance Inflation Factor, or VIF.\n",
        "\n",
        "* **Variance  Inflation Factor (VIF)**:  Variance inflation factors measure the inflation in the variances of the regression parameter estimates due to collinearities that exist among the predictors. It is a measure of how much the variance of the estimated regression coefficient $\\beta_k$ is \"inflated\" by the existence of correlation among the predictor variables in the model.\n",
        "    - If VIF is 1, then there is no correlation among the $k$th predictor and the remaining predictor variables, and hence, the variance of $\\beta_k$ is not inflated at all.\n",
        "\n",
        "* **General Rule of thumb**:\n",
        "    - If VIF is between 1 and 5, then there is low multicollinearity.\n",
        "    - If VIF is between 5 and 10, we say there is moderate multicollinearity.\n",
        "    - If VIF is exceeding 10, it shows signs of high multicollinearity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE6sSyDfqVR3"
      },
      "source": [
        "Let's define a function to check VIF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV-69rVWqH8g"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "\n",
        "def checking_vif(predictors):\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"feature\"] = predictors.columns\n",
        "\n",
        "    # calculating VIF for each feature\n",
        "    vif[\"VIF\"] = [\n",
        "        variance_inflation_factor(predictors.values, i)\n",
        "        for i in range(len(predictors.columns))\n",
        "    ]\n",
        "    return vif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC7xu368-qUO"
      },
      "outputs": [],
      "source": [
        "checking_vif(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtalwdoE-qUP"
      },
      "source": [
        "* There are multiple columns with very high VIF values, indicating presence of strong multicollinearity\n",
        "* We will systematically drop numerical columns with VIF > 5\n",
        "* We will ignore the VIF values for dummy variables and the constant (intercept)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSiS4SRaqH8q"
      },
      "source": [
        "### Removing Multicollinearity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gths8q5EIWzR"
      },
      "source": [
        "To remove multicollinearity\n",
        "\n",
        "1. Drop every column one by one that has a VIF score greater than 5.\n",
        "2. Look at the adjusted R-squared and RMSE of all these models.\n",
        "3. Drop the variable that makes the least change in adjusted R-squared.\n",
        "4. Check the VIF scores again.\n",
        "5. Continue till you get all VIF scores under 5.\n",
        "\n",
        "Let's define a function that will help us do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70XP3rDY-qUP"
      },
      "outputs": [],
      "source": [
        "def treating_multicollinearity(predictors, target, high_vif_columns):\n",
        "    \"\"\"\n",
        "    Checking the effect of dropping the columns showing high multicollinearity\n",
        "    on model performance (adj. R-squared and RMSE)\n",
        "\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    high_vif_columns: columns having high VIF\n",
        "    \"\"\"\n",
        "    # empty lists to store adj. R-squared and RMSE values\n",
        "    adj_r2 = []\n",
        "    rmse = []\n",
        "\n",
        "    # build ols models by dropping one of the high VIF columns at a time\n",
        "    # store the adjusted R-squared and RMSE in the lists defined previously\n",
        "    for cols in high_vif_columns:\n",
        "        # defining the new train set\n",
        "        train = predictors.loc[:, ~predictors.columns.str.startswith(cols)]\n",
        "\n",
        "        # create the model\n",
        "        olsmodel = sm.OLS(target, train).fit()\n",
        "\n",
        "        # adding adj. R-squared and RMSE to the lists\n",
        "        adj_r2.append(olsmodel.rsquared_adj)\n",
        "        rmse.append(np.sqrt(olsmodel.mse_resid))\n",
        "\n",
        "    # creating a dataframe for the results\n",
        "    temp = pd.DataFrame(\n",
        "        {\n",
        "            \"col\": high_vif_columns,\n",
        "            \"Adj. R-squared after_dropping col\": adj_r2,\n",
        "            \"RMSE after dropping col\": rmse,\n",
        "        }\n",
        "    ).sort_values(by=\"Adj. R-squared after_dropping col\", ascending=False)\n",
        "    temp.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfZR3GtN-qUP"
      },
      "outputs": [],
      "source": [
        "col_list = [\"watched\", \"votes\"]\n",
        "\n",
        "res = treating_multicollinearity(x_train, y_train, col_list)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3HKhIjY-qUP"
      },
      "outputs": [],
      "source": [
        "col_to_drop = \"votes\"\n",
        "x_train2 = x_train.loc[:, ~x_train.columns.str.startswith(col_to_drop)]\n",
        "x_test2 = x_test.loc[:, ~x_test.columns.str.startswith(col_to_drop)]\n",
        "\n",
        "# Check VIF now\n",
        "vif = checking_vif(x_train2)\n",
        "print(\"VIF after dropping \", col_to_drop)\n",
        "vif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogZ-IT0n-qUS"
      },
      "source": [
        "* We have dealt with multicollinearity in the data\n",
        "* Let's rebuild the model using the updated set of predictors variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydDGeeXG-qUS"
      },
      "outputs": [],
      "source": [
        "olsmod1 = sm.OLS(y_train, x_train2).fit()\n",
        "print(olsmod1.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM0uBl1o3UDi"
      },
      "source": [
        "### Interpreting the Regression Results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnjQ09Rk3LWk"
      },
      "source": [
        "4. **std err**: It reflects the level of accuracy of the coefficients.\n",
        "    - The lower it is, the higher is the level of accuracy.\n",
        "\n",
        "\n",
        "5. **P>|t|**: It is p-value.\n",
        "   \n",
        "    * For each independent feature, there is a null hypothesis and an alternate hypothesis. Here $\\beta_i$ is the coefficient of the $i$th independent variable.\n",
        "\n",
        "        - $H_o$ : Independent feature is not significant ($\\beta_i = 0$)\n",
        "        - $H_a$ : Independent feature is that it is significant ($\\beta_i \\neq 0$)\n",
        "\n",
        "    * (P>|t|) gives the p-value for each independent feature to check that null hypothesis. We are considering 0.05 (5%) as significance level.\n",
        "        \n",
        "        - A p-value of less than 0.05 is considered to be statistically significant.\n",
        "\n",
        "\n",
        "6. **Confidence Interval**: It represents the range in which our coefficients are likely to fall (with a likelihood of 95%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugvIKXJB-qUS"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "- We can see that adj. R-squared has dropped from 0.720 to 0.717, which shows that the dropped columns did not have much effect on the model\n",
        "- As there is no multicollinearity, we can look at the p-values of predictor variables to check their significance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccsFJFYoqH9J"
      },
      "source": [
        "### Dealing with high p-value variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj0CO6CS4jYF"
      },
      "source": [
        "- Some of the dummy variables in the data have p-value > 0.05. So, they are not significant and we'll drop them\n",
        "- But sometimes p-values change after dropping a variable. So, we'll not drop all variables at once\n",
        "- Instead, we will do the following:\n",
        "    - Build a model, check the p-values of the variables, and drop the column with the highest p-value\n",
        "    - Create a new model without the dropped feature, check the p-values of the variables, and drop the column with the highest p-value\n",
        "    - Repeat the above two steps till there are no columns with p-value > 0.05\n",
        "\n",
        "**Note**: The above process can also be done manually by picking one variable at a time that has a high p-value, dropping it, and building a model again. But that might be a little tedious and using a loop will be more efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFkO5oFj-qUT"
      },
      "outputs": [],
      "source": [
        "# initial list of columns\n",
        "predictors = x_train2.copy()\n",
        "cols = predictors.columns.tolist()\n",
        "\n",
        "# setting an initial max p-value\n",
        "max_p_value = 1\n",
        "\n",
        "while len(cols) > 0:\n",
        "    # defining the train set\n",
        "    x_train_aux = predictors[cols]\n",
        "\n",
        "    # fitting the model\n",
        "    model = sm.OLS(y_train, x_train_aux).fit()\n",
        "\n",
        "    # getting the p-values and the maximum p-value\n",
        "    p_values = model.pvalues\n",
        "    max_p_value = max(p_values)\n",
        "\n",
        "    # name of the variable with maximum p-value\n",
        "    feature_with_p_max = p_values.idxmax()\n",
        "\n",
        "    if max_p_value > 0.05:\n",
        "        cols.remove(feature_with_p_max)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "selected_features = cols\n",
        "print(selected_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4fj6umDqH9N"
      },
      "outputs": [],
      "source": [
        "x_train3 = x_train2[selected_features]\n",
        "x_test3 = x_test2[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCDUCG6_qH9R"
      },
      "outputs": [],
      "source": [
        "olsmod2 = sm.OLS(y_train, x_train3).fit()\n",
        "print(olsmod2.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nfdyeTW4Ilk"
      },
      "outputs": [],
      "source": [
        "# checking model performance on train set (seen 70% data)\n",
        "print(\"Training Performance\\n\")\n",
        "olsmod2_train_perf = model_performance_regression(olsmod2, x_train3, y_train)\n",
        "olsmod2_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3azyApn44Ilk"
      },
      "outputs": [],
      "source": [
        "# checking model performance on test set (seen 30% data)\n",
        "print(\"Test Performance\\n\")\n",
        "olsmod2_test_perf = model_performance_regression(olsmod2, x_test3, y_test)\n",
        "olsmod2_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85AyhdAfqH9z"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "* Now no feature has p-value greater than 0.05, so we'll consider the features in *x_train3* as the final set of predictor variables and *olsmod2* as the final model to move forward with\n",
        "* Now adjusted R-squared is 0.717, i.e., our model is able to explain ~72% of the variance\n",
        "* The adjusted R-squared in *olsmod1* (where we considered the variables without multicollinearity) was 0.717\n",
        "    * This shows that the variables we dropped were not affecting the model\n",
        "* RMSE and MAE values are comparable for train and test sets, indicating that the model is not overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctk29PsRqH90"
      },
      "source": [
        "**Now we'll check the rest of the assumptions on *olsmod2*.**\n",
        "\n",
        "2. **Linearity of variables**\n",
        "\n",
        "3. **Independence of error terms**\n",
        "\n",
        "4. **Normality of error terms**\n",
        "\n",
        "5. **No Heteroscedasticity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnOY6E5uqH-C"
      },
      "source": [
        "### TEST FOR LINEARITY AND INDEPENDENCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlczpHheIOEX"
      },
      "source": [
        "**Why the test?**\n",
        "\n",
        "* Linearity describes a straight-line relationship between two variables, predictor variables must have a linear relation with the dependent variable.\n",
        "* The independence of the error terms (or residuals) is important. If the residuals are not independent, then the confidence intervals of the coefficient estimates will be narrower and make us incorrectly conclude a parameter to be statistically significant.\n",
        "\n",
        "**How to check linearity and independence?**\n",
        "\n",
        "- Make a plot of fitted values vs residuals.\n",
        "- If they don't follow any pattern, then we say the model is linear and residuals are independent.\n",
        "- Otherwise, the model is showing signs of non-linearity and residuals are not independent.\n",
        "\n",
        "**How to fix if this assumption is not followed?**\n",
        "\n",
        "* We can try to transform the variables and make the relationships linear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgyzF2ii-qUT"
      },
      "outputs": [],
      "source": [
        "# let us create a dataframe with actual, fitted and residual values\n",
        "df_pred = pd.DataFrame()\n",
        "\n",
        "df_pred[\"Actual Values\"] = y_train  # actual values\n",
        "df_pred[\"Fitted Values\"] = olsmod2.fittedvalues  # predicted values\n",
        "df_pred[\"Residuals\"] = olsmod2.resid  # residuals\n",
        "\n",
        "df_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ4ivHQiqH-G"
      },
      "outputs": [],
      "source": [
        "# let's plot the fitted values vs residuals\n",
        "\n",
        "sns.residplot(\n",
        "    data=df_pred, x=\"Fitted Values\", y=\"Residuals\", color=\"purple\", lowess=True\n",
        ")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Fitted vs Residual plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdVdvRegqH-M"
      },
      "source": [
        "* The scatter plot shows the distribution of residuals (errors) vs fitted values (predicted values).\n",
        "\n",
        "* If there exist any pattern in this plot, we consider it as signs of non-linearity in the data and a pattern means that the model doesn't capture non-linear effects.\n",
        "\n",
        "* **We see no pattern in the plot above. Hence, the assumptions of linearity and independence are satisfied.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOxf_qsQqH-N"
      },
      "source": [
        "### TEST FOR NORMALITY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9VQtrfXIIIE"
      },
      "source": [
        "**Why the test?**\n",
        "\n",
        "* Error terms, or residuals, should be normally distributed. If the error terms are not normally distributed, confidence intervals of the coefficient estimates may become too wide or narrow. Once confidence interval becomes unstable, it leads to difficulty in estimating coefficients based on minimization of least squares. Non-normality suggests that there are a few unusual data points that must be studied closely to make a better model.\n",
        "\n",
        "**How to check normality?**\n",
        "\n",
        "* The shape of the histogram of residuals can give an initial idea about the normality.\n",
        "* It can also be checked via a Q-Q plot of residuals. If the residuals follow a normal distribution, they will make a straight line plot, otherwise not.\n",
        "* Other tests to check for normality includes the Shapiro-Wilk test.\n",
        "    - Null hypothesis: Residuals are normally distributed\n",
        "    - Alternate hypothesis: Residuals are not normally distributed\n",
        "\n",
        "**How to fix if this assumption is not followed?**\n",
        "\n",
        "* We can apply transformations like log, exponential, arcsinh, etc. as per our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUdQ6XJLqH-N"
      },
      "outputs": [],
      "source": [
        "sns.histplot(data=df_pred, x=\"Residuals\", kde=True)\n",
        "plt.title(\"Normality of residuals\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9YQpkZ-qH-Q"
      },
      "source": [
        "- The histogram of residuals does have a bell shape.\n",
        "- Let's check the Q-Q plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj8y7-1nqH-Q"
      },
      "outputs": [],
      "source": [
        "import pylab\n",
        "import scipy.stats as stats\n",
        "\n",
        "stats.probplot(df_pred[\"Residuals\"], dist=\"norm\", plot=pylab)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKlOF0TT-qUV"
      },
      "source": [
        "- The residuals more or less follow a straight line except for the tails.\n",
        "- Let's check the results of the Shapiro-Wilk test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1LIATpBqH-U"
      },
      "outputs": [],
      "source": [
        "stats.shapiro(df_pred[\"Residuals\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD0BLsvSqH-Z"
      },
      "source": [
        "- Since p-value < 0.05, the residuals are not normal as per the Shapiro-Wilk test.\n",
        "- Strictly speaking, the residuals are not normal.\n",
        "- However, as an approximation, we can accept this distribution as close to being normal.\n",
        "- **So, the assumption is satisfied.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gZ4GKY_qH-Z"
      },
      "source": [
        "### TEST FOR HOMOSCEDASTICITY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyJPcnJYIDJQ"
      },
      "source": [
        "* **Homoscedascity**: If the variance of the residuals is symmetrically distributed across the regression line, then the data is said to be homoscedastic.\n",
        "\n",
        "* **Heteroscedascity**: If the variance is unequal for the residuals across the regression line, then the data is said to be heteroscedastic.\n",
        "\n",
        "**Why the test?**\n",
        "\n",
        "* The presence of non-constant variance in the error terms results in heteroscedasticity. Generally, non-constant variance arises in presence of outliers.\n",
        "\n",
        "**How to check for homoscedasticity?**\n",
        "\n",
        "* The residual vs fitted values plot can be looked at to check for homoscedasticity. In the case of heteroscedasticity, the residuals can form an arrow shape or any other non-symmetrical shape.\n",
        "* The goldfeldquandt test can also be used. If we get a p-value > 0.05 we can say that the residuals are homoscedastic. Otherwise, they are heteroscedastic.\n",
        "    - Null hypothesis: Residuals are homoscedastic\n",
        "    - Alternate hypothesis: Residuals have heteroscedasticity\n",
        "\n",
        "**How to fix if this assumption is not followed?**\n",
        "\n",
        "* Heteroscedasticity can be fixed by adding other important features or making transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naX-iXItqH-b"
      },
      "outputs": [],
      "source": [
        "import statsmodels.stats.api as sms\n",
        "from statsmodels.compat import lzip\n",
        "\n",
        "name = [\"F statistic\", \"p-value\"]\n",
        "test = sms.het_goldfeldquandt(df_pred[\"Residuals\"], x_train3)\n",
        "lzip(name, test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzmt1AqYqH-d"
      },
      "source": [
        "**Since p-value > 0.05, we can say that the residuals are homoscedastic. So, this assumption is satisfied.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M24kMcA-qUW"
      },
      "source": [
        "## Predictions on test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbnr4QViqH-e"
      },
      "source": [
        "Now that we have checked all the assumptions of linear regression and they are satisfied, let's go ahead with prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAtayJx4Ge75"
      },
      "outputs": [],
      "source": [
        "# predictions on the test set\n",
        "pred = olsmod2.predict(x_test3)\n",
        "\n",
        "df_pred_test = pd.DataFrame({\"Actual\": y_test, \"Predicted\": pred})\n",
        "df_pred_test.sample(10, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KXrJHtFJvEu"
      },
      "source": [
        "- We can observe here that our model has returned pretty good prediction results, and the actual and predicted values are comparable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-G8CObN-qUX"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpEdqajh-qUX"
      },
      "source": [
        "Let's recreate the final model and print it's summary to gain insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxtxD00o557M"
      },
      "outputs": [],
      "source": [
        "x_train_final = x_train3.copy()\n",
        "x_test_final = x_test3.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDZD9zkmqH-x"
      },
      "outputs": [],
      "source": [
        "olsmodel_final = sm.OLS(y_train, x_train_final).fit()\n",
        "print(olsmodel_final.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCKvjTcd-qUX"
      },
      "outputs": [],
      "source": [
        "# checking model performance on train set (seen 70% data)\n",
        "print(\"Training Performance\\n\")\n",
        "olsmodel_final_train_perf = model_performance_regression(\n",
        "    olsmodel_final, x_train_final, y_train\n",
        ")\n",
        "olsmodel_final_train_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkjC-WAb-qUZ"
      },
      "outputs": [],
      "source": [
        "# checking model performance on test set (seen 30% data)\n",
        "print(\"Test Performance\\n\")\n",
        "olsmodel_final_test_perf = model_performance_regression(\n",
        "    olsmodel_final, x_test_final, y_test\n",
        ")\n",
        "olsmodel_final_test_perf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8CeR5BuqH-w"
      },
      "source": [
        "* The model is able to explain ~72% of the variation in the data\n",
        "\n",
        "* The train and test RMSE and MAE are low and comparable. So, our model is not suffering from overfitting\n",
        "\n",
        "* The MAPE on the test set suggests we can predict within 12.6% of the anime ratings\n",
        "\n",
        "* Hence, we can conclude the model *olsmodel_final* is good for prediction as well as inference purposes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvDRg5b-qUZ"
      },
      "source": [
        "## Conclusions and Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aXG5ChnU-MW"
      },
      "source": [
        "1. The model is able to explain ~72% of the variation in the data and within 12.6% of the anime ratings on the test data, which is good\n",
        "    - This indicates that the model is good for prediction as well as inference purposes\n",
        "\n",
        "\n",
        "2. If the duration of an anime increases by one unit, then its rating increases by 0.0123 units, all other variables held constant\n",
        "\n",
        "\n",
        "3. If the number of people watching an anime increases by one unit, then its rating increases by 0.0031 units, all other variables held constant\n",
        "\n",
        "\n",
        "4. If the number of years an anime is running increases by one unit, then its rating decreases by 0.0762 units, all other variables held constant\n",
        "\n",
        "\n",
        "5. The rating for anime released for TV will be 0.5598 units less than those released as DVD specials\n",
        "\n",
        "\n",
        "6. As the anime rating increase with an increase in the number of people watching it, the company can improve its marketing activities to promote their content\n",
        "\n",
        "\n",
        "7. As the anime rating increase with an increase in its duration, the company can look to add more anime to their portal which have longer episodes\n",
        "\n",
        "\n",
        "8. Streamist can look to increase the number of anime under the Drama and Comedy genres as they are the most watched anime on the platform\n",
        "\n",
        "\n",
        "9. Streamist can gather data about their users like age, gender, geographical location, occupation, etc. to better understand the kind of web series and movies different users like"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2eFxAmjC-PS"
      },
      "source": [
        "## <a name='link1'>Appendix: Detailed Exploratory Data Analysis (EDA)</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7Drz5w_9WKV"
      },
      "source": [
        "### Univariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRit2ng4C-PT"
      },
      "source": [
        "#### `rating`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlrjYGQ7C-PU"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"rating\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7aRgpV9C-PU"
      },
      "source": [
        "* The anime ratings are kind of normally distributed with much fatter tails."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzgpKviZC-PU"
      },
      "source": [
        "#### `eps`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtilBvGZC-PV"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"eps\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeYHag9vC-PV"
      },
      "source": [
        "* The distribution is right-skewed, as there are many anime movies in the data and they are considered to be of only one episode (as per data description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_oyZypWC-PV"
      },
      "source": [
        "#### `duration`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jopRgpt3C-PW"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"duration\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNqEDGnmC-PW"
      },
      "source": [
        "* The distribution is right-skewed with a median runtime of less than 10 minutes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WQPFzj3C-PW"
      },
      "source": [
        "#### `watched`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd4-V5DZC-PX"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"watched\", bins=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSHp9jFC-PX"
      },
      "source": [
        "* The distribution is heavily right-skewed, and most of the anime having less than 500 viewers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0HuTkCZ-qT9"
      },
      "source": [
        "#### `watching`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Sasnymu-qT-"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"watching\", bins=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrgv5GgZ-qT-"
      },
      "source": [
        "* The distribution is heavily right-skewed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAUNOPfD-qT-"
      },
      "source": [
        "#### `votes`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zYTPbEi-qT-"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"votes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rERweGdq-qT-"
      },
      "source": [
        "* The distribution is heavily right-skewed and seems to be bimodal, with most anime having less than 250 or more 2500 votes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1KlwUmZC-PY"
      },
      "source": [
        "#### `startYr`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh-07HzPC-PY"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"startYr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnykIfCRC-PY"
      },
      "source": [
        "* The distribution is left-skewed and most of the anime have started after 2005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifrwici9-qT_"
      },
      "source": [
        "#### `finishYr`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ER4ttK--qT_"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(df, \"finishYr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7b_Vv97-qT_"
      },
      "source": [
        "* The distribution is left-skewed and most of the anime have finished after 2005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR9X9L_-C-PZ"
      },
      "source": [
        "#### `mediaType`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL1Uk0GMC-Pa"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(df, \"mediaType\", perc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8ozGcL6C-Pa"
      },
      "source": [
        "* Most of the anime are released for TV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V-qgjXoC-Pc"
      },
      "source": [
        "#### `studio_primary`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wcisb15C-Pd"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(df, \"studio_primary\", perc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmtqCgDrC-Pd"
      },
      "source": [
        "* *Toei Animation* is the most common studio among the available studio names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXvNuAkM-qUA"
      },
      "source": [
        "#### `studios_colab`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuKhW845-qUA"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(df, \"studios_colab\", perc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfk_2jAs-qUA"
      },
      "source": [
        "- More than 95% of the anime in the data do not involve a collaboration between studios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhVVnISF-qUB"
      },
      "source": [
        "#### `contentWarn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwI4FmcU-qUB"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(df, \"contentWarn\", perc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UZaM9mO-qUB"
      },
      "source": [
        "- Nearly 90% of the anime in the data do not have an associated content warning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jS63iRW9WKs"
      },
      "source": [
        "### Bivariate analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2MNEP5oC-Pf"
      },
      "source": [
        "#### Correlation Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knpmI2Eg-qUB"
      },
      "outputs": [],
      "source": [
        "# creating a list of numerical columns\n",
        "num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# dropping start and finish year from list of numerical columns as they are not numerical in nature\n",
        "num_cols.remove(\"startYr\")\n",
        "num_cols.remove(\"finishYr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHG40JlXC-Pg"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "sns.heatmap(\n",
        "    df[num_cols].corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\"\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwfq9zp6C-Pg"
      },
      "source": [
        "* The rating of an anime is highly correlated with the number of people who have watched the anime and voted for it on the portal\n",
        "* The number of people who have watched the anime is highly correlated with the number of people who are watching the anime\n",
        "* The number of people who have watched the anime is very highly correlated with the number of people who have voted for the anime on the portal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_aGPpebC-Ph"
      },
      "source": [
        "#### Let's check the variation in the anime ratings with some of the categorical columns in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKj1Aen5C-Ph"
      },
      "source": [
        "#### `genre` vs `rating`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEQHT16wC-Ph"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "sns.boxplot(data=df, x=\"genre\", y=\"rating\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAmMe1xXC-Pi"
      },
      "source": [
        "* Anime under the genre of Drama are rated the highest in general, while those under the genre of Comedy and rated the least"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH-kUvv8C-Pi"
      },
      "source": [
        "#### `genre` vs `watched`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJZwa4qkC-Pj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "sns.boxplot(data=df, x=\"genre\", y=\"watched\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vygG3mQtC-Pj"
      },
      "source": [
        "* Anime under the genres of Drama and Romance have higher viewership in general"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuLAO_iW-qUD"
      },
      "source": [
        "#### `mediaType` vs `rating`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qSK0w7a-qUD"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"mediaType\", y=\"rating\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlJLTZ4A-qUD"
      },
      "source": [
        "* Anime available as web series or music videos have a lower rating in general"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eFcfrGw-qUE"
      },
      "source": [
        "#### `mediaType` vs `watched`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf-3QLgO-qUE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"mediaType\", y=\"watched\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC5CudzB-qUE"
      },
      "source": [
        "* Anime released as web series and music videos have lower viewership in general"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drG1KGuKC-Pj"
      },
      "source": [
        "#### `studio_primary` vs `rating`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufBa2ZlQC-Pk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"studio_primary\", y=\"rating\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-3RqoahC-Pk"
      },
      "source": [
        "* The ratings are low for anime created by *OLM* studios in general\n",
        "* Ratings are also low, in general, for anime created by studios other than the ones in the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw062Wxa-qUF"
      },
      "source": [
        "#### `mediaType` vs `duration`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MMkQ91i-qUF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"mediaType\", y=\"duration\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-RFeE0o-qUF"
      },
      "source": [
        "* Anime movies have the highest duration while music videos have the lowest, which is expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEBq3KCA-qUF"
      },
      "source": [
        "#### `mediaType` vs `eps`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqLabkwt-qUF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"mediaType\", y=\"eps\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1fQLaRj-qUF"
      },
      "source": [
        "* Anime movies have seem to have exactly one episode, which is in line with the data description\n",
        "* Anime released for TV have the highest number of episodes (more than 20) in general"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXrsRQHj-qUG"
      },
      "outputs": [],
      "source": [
        "df[df.mediaType == \"Movie\"][\"eps\"].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Rk58f3-qUG"
      },
      "source": [
        "* This confirms that anime movies have exactly one episode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-e0g7JH4Ild"
      },
      "source": [
        "#### `genre` vs `watched`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzhIsv7k4Ild"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"genre\", y=\"watched\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec7F4YgN4Ild"
      },
      "source": [
        "* Anime from the Drama and Comedy genres have been watched more in general"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1eRXyxl4Ild"
      },
      "source": [
        "#### `genre` vs `watching`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO65K0EV4Ild"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x=\"genre\", y=\"watching\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULq1oySS4Ile"
      },
      "source": [
        "* Anime from the Drama and Comedy genres are being watched more in general"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFzgqrtFoHNk"
      },
      "source": [
        "### To jump back to the EDA summary section, click <a href = #link2>here</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wczeLO4oIIw"
      },
      "source": [
        "___"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rj3ZBcwc-qTr",
        "F3Tm5SxJTle6",
        "xxhpZv9y-qTw",
        "aodMV5D3-qTy",
        "VjmJBEKSQjcH",
        "kQ5wsxwA-qUG",
        "wYF-RsrNqH0E",
        "iqLh_w63-qUJ",
        "TeuhzPWVbtGq",
        "1THqC335b4Yi",
        "G9_JGYY_-qUN",
        "a9GxSQf-qH8e",
        "-M24kMcA-qUW",
        "A-G8CObN-qUX",
        "7uvDRg5b-qUZ",
        "D2eFxAmjC-PS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}